{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff704263",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# STA 141B Data & Web Technologies for Data Analysis\n",
    "\n",
    "### Lecture 7, 2/1/24, APIs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d720fbd5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    " - HW 2 due next Friday"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d6f0bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Today's topics\n",
    "\n",
    "- Final project\n",
    "- Getting Data from the Web\n",
    "- Hypertext Transfer Protocol\n",
    "- Representational State Transfer\n",
    "- iTunes API\n",
    "- Caching\n",
    "- API Keys\n",
    "- Guardian API\n",
    "\n",
    "### Resources\n",
    " - [iTunes Search API](https://affiliate.itunes.apple.com/resources/documentation/itunes-store-web-service-search-api/)\n",
    " - [Guardian API](https://open-platform.theguardian.com/documentation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54e29e3",
   "metadata": {},
   "source": [
    "### Final Project\n",
    "\n",
    "You should work alone or with up to two partners. The\n",
    "purpose of the project is to provide you with real data aquisition experience,\n",
    "which includes:\n",
    "\n",
    "* Posing questions / finding challenges\n",
    "* Finding data sources\n",
    "* Accessing the data \n",
    "* Processing the data \n",
    "* Exploring and visualizing the data\n",
    "* Presenting your findings through writing\n",
    "\n",
    "#### Getting Started\n",
    "\n",
    "To narrow down your project to just one topic, think\n",
    "about:\n",
    "\n",
    "*   What questions does your topic address or what problems does your topic\n",
    "    solve? Why and to whom are these meaningful?\n",
    "*   What's challenging about your topic?\n",
    "*   Are there credible, **public** datasets available to explore the topic?\n",
    "    See below for some suggested data sources.\n",
    "*   Is a 6-week project long enough to explore the topic reasonably well?\n",
    "\n",
    "As inspiration and an example of what can be done with public datasets, see [I\n",
    "Quant NY][NY]. \n",
    "\n",
    "[NY]: http://iquantny.tumblr.com/post/144197004989/the-nypd-was-systematically-ticketing-legally\n",
    "\n",
    "#### Grading criteria\n",
    "\n",
    "The final report is due on __March 20__. The report should be 8-10 pages\n",
    "including writing and visualizations, but excluding code. \n",
    "\n",
    "We will score your report according to:\n",
    "\n",
    "* Reporting (20%): Are there clear research questions that you asked, and did you\n",
    "    address these in an orderly fashion? Did you make well justified\n",
    "    conclusions? Is your project sensible and easy to read?\n",
    "* Data Aquisition and Processing (50%):  How much work was necessary to get your data,\n",
    "    which includes web APIs, web scraping, and reading data from files. \n",
    "    Did you process the data in an clear, efficient,\n",
    "    and organized way? Do you join multiple data sources appropriately? Did you\n",
    "    work with unstructured data? Did you store your processed data in an\n",
    "    efficient way, using well-thought-out data structures or a database?\n",
    "* Vizualisation and Methodology (20%): \n",
    "    Do your visualizations follow best practices? Do they support the hypothesis? \n",
    "    Is your methodology appropriate? \n",
    "    Does this give insight to your project? Are the methods tailored to your\n",
    "    specific topic and data (not generic or off-the-shelf)?\n",
    "* Code (10%): Is your code well-organized and easy to read? Is your code\n",
    "    reproducible? Is your code documented? Is your code reasonably efficient?\n",
    "    Did you use appropriate data structures and algorithms?\n",
    "\n",
    "Grading scales:\n",
    "\n",
    "Grade            | Points\n",
    "------------     | -------\n",
    "Good             | 10\n",
    "Satisfactory     | 8\n",
    "Poor             | 6\n",
    "Partial Work     | 4\n",
    "No Work          | 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ccd60",
   "metadata": {},
   "source": [
    "### Getting Data from the Web\n",
    "\n",
    "We consider three ways one can get data from the web, from most to least convenient:\n",
    "1. Direct download\n",
    "2. API\n",
    "3. Scraping\n",
    "\n",
    "Always look for a direct download first!\n",
    "\n",
    "##### Difference between web scraping and API\n",
    "\n",
    "_Web Scraping_ refers to the process of extracting data from a website or specific webpage.\n",
    "\n",
    "API stands for _application programming interface_ (API) is a collection of functions and data structures for communicating with other software. For instance, whenever you use a Python package, you're using the API created by the package's developers.\n",
    "\n",
    "The goal of both web scraping and (web) APIs is to access web data.\n",
    "\n",
    "Web scraping allows you to extract data from any website through the use of web scraping software. On the other hand, APIs give you direct access to the data you want.\n",
    "\n",
    "Websites sometimes provide an API so that programmers can access content without web scraping. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a17e5",
   "metadata": {},
   "source": [
    "### Hypertext Transfer Protocol\n",
    "\n",
    "The hypertext transfer protocol (HTTP) is a set of rules for communicating over the internet.\n",
    "\n",
    "For example, your web browser uses HTTP every time you visit a web page. The browser makes a _request_ to the server for the page, and if nothing goes wrong, the server _responds_ with the page. If you have Firefox or Chrome, you can inspect these requests with your browser's web developer tools (Windows: <kbd>Ctrl</kbd> + <kbd>i</kbd>; MacOS: <kbd>&#8984;</kbd> + <kbd>&#8997;</kbd> + <kbd>i</kbd>).\n",
    "\n",
    "Several [different kinds of HTTP requests](https://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol#Request_methods) are possible. Think of these as the different \"verbs\" you can use when communicating in HTTP.\n",
    "\n",
    "Many protocols exist for communicating over the internet. For instance, you may have heard of _file transfer protocol_ (FTP) for transferring files, or _simple mail transfer protocol_ (SMTP) for sending/receiving email. However, web APIs almost always use HTTP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f833f87",
   "metadata": {},
   "source": [
    "A response to an HTTP request always includes a status code that summarizes whether the request was successful. Wikipedia has a full [list of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes). Generally,\n",
    "\n",
    "* 200-299: Your request succeeded.\n",
    "* 300-399: You need to take further action to complete the request.\n",
    "* 400-499: Your request wasn't valid (you made a mistake). You've probably seen 404 before!\n",
    "* 500-599: Your request failed (the server made a mistake)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b912b2",
   "metadata": {},
   "source": [
    "### Representational State Transfer \n",
    "\n",
    "The most popular kind of web API is a _representational state transfer_ (REST) API. The API needs to meet the following architectural requirements to be considered a REST API:\n",
    "\n",
    "- Client-server: REST applications have a server that manages application data and state. \n",
    "- Stateless: Servers don’t maintain client state, clients manage their own application state. The client’s requests to the server contain all the information required to process them.\n",
    "- Cacheable: servers must mark their responses as cacheable or not. Systems and clients can cache responses when convenient to improve performance. \n",
    "- Uniform interface: This is REST’s most well-known feature or rule. \n",
    "\n",
    "The URL with which we can talk to the server is sometimes called *endpoint*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed225a4",
   "metadata": {},
   "source": [
    "### iTunes API\n",
    "\n",
    "We use the iTunes API at `https://itunes.apple.com/search`, see [documentation](https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/iTuneSearchAPI/Searching.html#//apple_ref/doc/uid/TP40017632-CH5-SW1). \n",
    "\n",
    "When you first use a web API, check the documentation to find out what the endpoints are and what kind of HTTP requests to use. If the documentation doesn't mention what kind of HTTP request to use, then GET is usually the right choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250f35d",
   "metadata": {},
   "source": [
    "#### Making Requests\n",
    "\n",
    "Python's `requests` package provides functions for making HTTP requests. Let's use the endpoint we learned from the iTunes API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2898ddd1",
   "metadata": {},
   "source": [
    "The syntax for the `requests` package is `response = requests.get(\"WEBSITE ADDRESS\")`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5340d169",
   "metadata": {},
   "source": [
    "#### Query Strings\n",
    "\n",
    "Most of the functions we use have parameters, and you can pass arguments for those parameters when you call a function.\n",
    "\n",
    "Endpoints in REST APIs work the same way, but the syntax is different. You can pass arguments by adding `?PARAMETER=ARGUMENT` to the end of the URL. Parameter and argument pairs are separated by `&`. This syntax is called a _query string_.\n",
    "\n",
    "The search endpoint is `https://itunes.apple.com/search`, and the documentation lists several parameters. We can use `requests` to build the query string automatically.\n",
    "\n",
    "Lets answer the question: How many albums of *Beyoncé* are on iTunes? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa83ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://itunes.apple.com/search\", params = {\n",
    "        \"term\": \"beyonce\", # add multiple terms via +\n",
    "        \"media\": \"music\",\n",
    "        \"entity\": \"album\",\n",
    "        \"attribute\": \"artistTerm\", # check iTunes docs\n",
    "        \"country\": \"US\", \n",
    "        \"limit\": \"1\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8cec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d63224",
   "metadata": {},
   "source": [
    "You can have `requests` check the status for you with the `.raise_for_status()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60075d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca2460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://itunes.apple.com/search\", params = {\n",
    "        \"term\": \"beyonce\", \n",
    "        \"media\": \"music\",\n",
    "        \"entity\": \"album\",\n",
    "        \"attribute\": \"artistTerm\", # artistsTerm is no valid attribute! \n",
    "        \"country\": \"US\", \n",
    "        \"limit\": \"200\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274aeab9",
   "metadata": {},
   "source": [
    "Once you have the response, now what? Where's the data? Different web APIs use different formats. Again, see the documentation. Two common formats are:\n",
    "\n",
    " - _JavaScript Object Notation_ (JSON): JSON looks and works a lot like Python lists and dictionaries. Lists are surrounded with `[ ]`, and dictionaries are surrounded with `{ }`. There are many Python libraries for reading JSON into lists and dictionaries. Jupyter notebooks are an example of a file in JSON format.\n",
    "\n",
    " - _eXtensible Markup Language_ (XML): XML uses \"tags\" denoted by `< >` to mark up sections of text. We'll learn more about XML when we learn about web scraping, since XML is very similar to hypertext markup language (HTML), the language used to build web pages.\n",
    "\n",
    "The iTunes returns data in JSON format (derived from JavaScript). We can inspect the raw content (bytes) of a response with the `.content` attribute. If we know the response is in a text format, we can use `.text` to see the content as an ordinary Python string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d887e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2587d2",
   "metadata": {},
   "source": [
    "Since the response we got is in JSON format, we'd like to convert the string to lists and dictionaries. The `requests` package provides a method `.json()` to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424b81b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = response.json()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4b680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45609a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results = pd.DataFrame(result['results'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9c3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972cec14",
   "metadata": {},
   "source": [
    "### Caching\n",
    "\n",
    "Making an HTTP request is not free! It has a real cost in CPU time and also cash. Server administrators will not appreciate it if you make too many requests or make requests too quickly. So:\n",
    "\n",
    "* Use `time.sleep()` to slow down any requests you make in a loop. Aim for no more than 20-30 requests per second.\n",
    "* Install and use the `requests_cache` package to avoid downloading extra data when you make the same request twice.\n",
    "\n",
    "Failing to be polite can get you banned from websites!\n",
    "\n",
    "We can use `sleep` from `time` to suspend any operation for the passed number of seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf44d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "print(time.ctime())\n",
    "time.sleep(5)\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9183f06d",
   "metadata": {},
   "source": [
    "A possible problem for time consuming requests is that data is requested multiple times. This can be avoided by using a cache. When the request is made, it first checks the cache. Only if the data is not found there, the data is pulled from the server and copied into the cache. \n",
    "\n",
    "We cache our search results with `requests_cache` ([docs](https://requests-cache.readthedocs.io/en/v0.9.6/user_guide.html)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580bda00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "session = requests.Session() \n",
    "print(time.ctime())\n",
    "for i in range(10):\n",
    "    session.get('http://httpbin.org/delay/1') # this endpoints delays by one second\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c1e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests_cache\n",
    "session = requests_cache.CachedSession('demo_cache')\n",
    "print(time.ctime())\n",
    "for i in range(10):\n",
    "    res = session.get('http://httpbin.org/delay/1')\n",
    "print(time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40666a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b26e9a",
   "metadata": {},
   "source": [
    "### API Keys\n",
    "\n",
    "Many APIs use a _key_ or _token_ to identify the user. For instance, The Guardian, a British newspaper, provides a [web API](https://open-platform.theguardian.com/) to access their news articles. You need an API key to use their web APIs. You can get one for free [here](https://bonobo.capi.gutools.co.uk/register/developer).\n",
    "\n",
    "#### Storing API Keys\n",
    "\n",
    "Your API key is private and your responsibility. Treat it like a password. Keep it secret! \n",
    "\n",
    "In order to keep your API key separate from your code:\n",
    "1. Save the API key in a text file.\n",
    "2. Use Python to load the API key into a variable.\n",
    "\n",
    "Python's built-in `open()` function opens a file, and the `.readline()` method reads a line from a file. Often you'll see these used with `with`, which automatically closes the file at the end of the block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36efeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_key(keyfile):\n",
    "    with open(keyfile) as f:\n",
    "        return f.readline().strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b37d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = read_key(\"../keys/guardian.txt\") # Don't print out your actual API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e288d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5489ff",
   "metadata": {},
   "source": [
    "Now you can use the `key` variable anywhere you need the actual API key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d413d",
   "metadata": {},
   "source": [
    "#### Querying The Guardian\n",
    "\n",
    "We've got our key, so let's use The Guardian API. \n",
    "\n",
    "We want to answer the question whether Biden or Trump get more newspaper coverage in the days leading up to the 2020 U.S. presidential election. Let's start by trying to get all of the articles about one of the candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba089b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://content.guardianapis.com/search\", params = {\n",
    "        \"api-key\": key,\n",
    "        \"q\": \"Biden\",\n",
    "        \"from-date\": \"2020-11-01\",\n",
    "        \"to-date\": \"2020-11-10\",\n",
    "        \"page-size\": 50,\n",
    "        \"order_by\": \"newest\",\n",
    "        \"page\": 1\n",
    "    }) # try page 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1daf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.raise_for_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea0682",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3962d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def get_articles(q, page = 1, from_date = \"2020-11-01\"):\n",
    "    time.sleep(0.05) \n",
    "    response = requests.get(\"https://content.guardianapis.com/search\", params = {\n",
    "        \"api-key\": key,\n",
    "        \"q\": q,\n",
    "        \"from-date\": from_date,\n",
    "        \"to-date\": \"2020-11-10\",\n",
    "        \"page-size\": 50,\n",
    "        \"order_by\": \"newest\", \n",
    "        \"page\": page\n",
    "    })\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29c5881",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "biden = get_articles(\"Biden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = biden[\"pages\"]\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd9813",
   "metadata": {},
   "outputs": [],
   "source": [
    "pageSize = biden[\"pageSize\"]\n",
    "pageSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentPage = biden[\"currentPage\"]\n",
    "currentPage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18f2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = biden[\"results\"]\n",
    "for p in range(2, pages + 1):\n",
    "    results += get_articles(\"biden\", p)[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0563b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96ced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a172a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545ebb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a4a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd86a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"webPublicationDate\"] = pd.to_datetime(df[\"webPublicationDate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ab910",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df[\"webPublicationDate\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca0e724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = df[\"webPublicationDate\"].dt\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbbfa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "date.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf79cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.DataFrame({\"day\": date.day, \"day_name\": date.day_name()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9513c12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c956922",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates.groupby([\"day\", \"day_name\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5211ad",
   "metadata": {},
   "source": [
    "Write it as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4317858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_articles(q, page = 1):\n",
    "    response = requests.get(\"https://content.guardianapis.com/search\", params = {\n",
    "        \"api-key\": key,\n",
    "        \"q\": q,\n",
    "        \"from-date\": \"2020-11-01\",\n",
    "        \"to-date\": \"2020-11-10\",\n",
    "        \"page-size\": 50,\n",
    "        \"page\": page\n",
    "    })\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b412d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_articles(q, time_sleep = 0.05):\n",
    "    # Get the first page, and find out how many pages there are.\n",
    "    candidate = get_articles(q)\n",
    "    pages = candidate[\"pages\"]\n",
    "\n",
    "    # Loop over remaining pages.\n",
    "    results = candidate[\"results\"]\n",
    "    for p in range(2, pages + 1):\n",
    "        results += get_articles(q, p)[\"results\"]\n",
    "        time.sleep(time_sleep)\n",
    "\n",
    "    # Convert the articles to data frame, and the date column to a date.\n",
    "    df = pd.DataFrame(results)\n",
    "    df[\"webPublicationDate\"] = pd.to_datetime(df[\"webPublicationDate\"])\n",
    "    \n",
    "    # Get the day and day name, then count them.\n",
    "    date = df[\"webPublicationDate\"].dt\n",
    "    dates = pd.DataFrame({\"day\": date.day, \"day_name\": date.day_name()})\n",
    "    return dates.groupby([\"day\", \"day_name\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0fa9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden=get_all_articles(\"Biden\")\n",
    "biden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43a26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e6d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "trump=get_all_articles(\"Trump\")\n",
    "trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482bc398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([biden,trump]).T\n",
    "df = df.rename(columns={0: 'Biden', 1: 'Trump'})\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fba6d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.melt(id_vars = ['day', 'day_name'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e6c872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine as p9\n",
    "(\n",
    "    p9.ggplot(df, p9.aes(x='day',y='value',color='variable')) + \n",
    "        p9.geom_line() + \n",
    "    p9.labs(color='',x='Day',y='Number of articles')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d50132",
   "metadata": {},
   "source": [
    "What are some ways this analysis could be improved?\n",
    "\n",
    "* Check that articles about \"Trump\" and \"Biden\" are actually about the two candidates. Some may be about other things -- the English word \"trump\", \"Hunter Biden\", etc...\n",
    "* Check whether the API searches article text or just article titles.\n",
    "* Use more sources, and use American newspapers (unless the goal was to analyze international news).\n",
    "* Make visualizations.\n",
    "* Use a larger time window.\n",
    "* Use other kinds of data (e.g., poll results) to look for relationships.\n",
    "\n",
    "Collecting and cleaning data takes a lot of very technical work, but it's only the first step in the analysis. When you finish data collection and cleaning, it can feel like you're finally done. Take a moment to congratulate yourself and step away from the data, so that when you come back you'll be ready to do a careful statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4842a995",
   "metadata": {},
   "source": [
    "### OAuth\n",
    "\n",
    "[OAuth](https://en.wikipedia.org/wiki/OAuth) is a way to give an application access to data on a website or web API.\n",
    "\n",
    "You might run into OAuth if you use a web API where the data is private. For instance, Twitter provides a [web API](https://developer.twitter.com/en/docs.html) for managing your personal Twitter account. If you want to access the API from a Python script, first you have to use OAuth to tell Twitter that the script has permission to use your data.\n",
    "\n",
    "OAuth can operate in several different ways. As always, check the documentation for the web API you want to use in order to find out what you need to do.\n",
    "\n",
    "The simplest case of OAuth requires scripts to have a key or token from the web API provider. This is very similar to using an API key.\n",
    "\n",
    "For more complicated cases, the `requests-ouathlib` package ([docs](https://requests-oauthlib.readthedocs.io/en/latest/)) may help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c15a9a",
   "metadata": {},
   "source": [
    "### Summary \n",
    "\n",
    "- Third parties provide access to their data bases via APIs\n",
    "- Check API documentation to assemble a valid query\n",
    "- You are a guest, be polite! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
